root@hadoop-master:~# $HADOOP_HOME/bin/hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar \
>     -files /root/TFIDF_mapper.py,/root/TFIDF_reducer.py \
>     -input /user/root/input/wc_data1.txt \
>     -input /user/root/input/wc_data2.txt \
>     -output /user/root/output_tf_idf \
>     -mapper "python3 TFIDF_mapper.py" \
>     -reducer "python3 TFIDF_reducer.py"
packageJobJar: [/tmp/hadoop-unjar1739657232480054409/] [] /tmp/streamjob4208004153389037506.jar tmpDir=null
24/10/31 10:00:49 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/10/31 10:00:49 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/10/31 10:00:49 INFO mapred.FileInputFormat: Total input paths to process : 2
24/10/31 10:00:49 INFO mapreduce.JobSubmitter: number of splits:2
24/10/31 10:00:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1730364799437_0006
24/10/31 10:00:49 INFO impl.YarnClientImpl: Submitted application application_1730364799437_0006
24/10/31 10:00:50 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1730364799437_0006/
24/10/31 10:00:50 INFO mapreduce.Job: Running job: job_1730364799437_0006
24/10/31 10:00:55 INFO mapreduce.Job: Job job_1730364799437_0006 running in uber mode : false
24/10/31 10:00:55 INFO mapreduce.Job:  map 0% reduce 0%
24/10/31 10:01:00 INFO mapreduce.Job:  map 100% reduce 0%
24/10/31 10:01:05 INFO mapreduce.Job:  map 100% reduce 100%
24/10/31 10:01:05 INFO mapreduce.Job: Job job_1730364799437_0006 completed successfully
24/10/31 10:01:05 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=435
		FILE: Number of bytes written=363089
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=307
		HDFS: Number of bytes written=516
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=5280
		Total time spent by all reduces in occupied slots (ms)=2718
		Total time spent by all map tasks (ms)=5280
		Total time spent by all reduce tasks (ms)=2718
		Total vcore-milliseconds taken by all map tasks=5280
		Total vcore-milliseconds taken by all reduce tasks=2718
		Total megabyte-milliseconds taken by all map tasks=5406720
		Total megabyte-milliseconds taken by all reduce tasks=2783232
	Map-Reduce Framework
		Map input records=2
		Map output records=18
		Map output bytes=393
		Map output materialized bytes=441
		Input split bytes=212
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=441
		Reduce input records=18
		Reduce output records=15
		Spilled Records=36
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=55
		CPU time spent (ms)=1810
		Physical memory (bytes) snapshot=870027264
		Virtual memory (bytes) snapshot=2717433856
		Total committed heap usage (bytes)=603979776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=516
24/10/31 10:01:05 INFO streaming.StreamJob: Output directory: /user/root/output_tf_idf
root@hadoop-master:~# $HADOOP_HOME/bin/hdfs dfs -cat /user/root/output/part-00000
cat: `/user/root/output/part-00000': No such file or directory
root@hadoop-master:~# $HADOOP_HOME/bin/hdfs dfs -cat /user/root/output_tf_idf/part-00000
DEBUG: Total documents = 2	
DEBUG: DF count for word 'drink': 2	
DEBUG: DF count for word 'love': 2	
DEBUG: DF count for word 'larger': 1	
DEBUG: DF count for word 'and': 2	
DEBUG: DF count for word 'i': 2	
DEBUG: DF count for word 'eu': 1	
DEBUG: DF count for word 'ale': 1	
DEBUG: DF count for word 'japanese': 1	
DEBUG: DF count for word 'germany': 1	
DEBUG: DF count for word 'craft': 1	
DEBUG: DF count for word 'in': 2	
DEBUG: DF count for word 'beer': 2	
beer	wc_data1.txt	0.000000
beer	wc_data2.txt	0.000000