{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "path = \"testcase/wc_data1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sort algorithm\n",
    "\n",
    "def hash_function(key):\n",
    "\n",
    "    if key[0].lower() < 'm':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapper Output (with partition):\n",
      "I\t1\tPartition: 0\n",
      "love\t1\tPartition: 0\n",
      "drink\t1\tPartition: 0\n",
      "craft\t1\tPartition: 0\n",
      "beer\t1\tPartition: 0\n",
      "and\t1\tPartition: 0\n",
      "larger\t1\tPartition: 0\n",
      "beer\t1\tPartition: 0\n",
      "in\t1\tPartition: 0\n",
      "Germany\t1\tPartition: 0\n"
     ]
    }
   ],
   "source": [
    "# mapper.py\n",
    "\n",
    "mapper_output = []\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        words = line.split()\n",
    "        \n",
    "        for word in words:\n",
    "\n",
    "            partition = hash_function(word)\n",
    "            mapper_output.append((word, 1, partition))\n",
    "\n",
    "print(\"Mapper Output (with partition):\")\n",
    "for output in mapper_output:\n",
    "    print(f'{output[0]}\\t{output[1]}\\tPartition: {output[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and Sort\n",
    "\n",
    "partitioned_mapper_output = {}\n",
    "\n",
    "for word, count, partition in mapper_output:\n",
    "    if partition not in partitioned_mapper_output:\n",
    "        partitioned_mapper_output[partition] = []\n",
    "    partitioned_mapper_output[partition].append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by word (key) across partitions\n",
    "sorted_output = []\n",
    "for partition in partitioned_mapper_output:\n",
    "    partitioned_mapper_output[partition].sort(key=itemgetter(0))\n",
    "    sorted_output.extend(partitioned_mapper_output[partition])\n",
    "\n",
    "# Sort the final combined output by the word\n",
    "sorted_output.sort(key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reducer Output:\n",
      "Germany\t1\n",
      "I\t1\n",
      "and\t1\n",
      "beer\t2\n",
      "craft\t1\n",
      "drink\t1\n",
      "in\t1\n",
      "larger\t1\n",
      "love\t1\n"
     ]
    }
   ],
   "source": [
    "# Reducer\n",
    "\n",
    "print(\"\\nReducer Output:\")\n",
    "current_word = None\n",
    "current_count = 0\n",
    "\n",
    "for word, count in sorted_output:\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            print(f'{current_word}\\t{current_count}')\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "# Print the last word count\n",
    "if current_word == word:\n",
    "    print(f'{current_word}\\t{current_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pattern_in_files(file_paths, search_pattern):\n",
    "    \"\"\" Search for the pattern in the given files and return the matching lines for each file. \"\"\"\n",
    "    \n",
    "    pattern = re.compile(search_pattern)\n",
    "    file_matches = {}\n",
    "    \n",
    "    # Iterate through the files\n",
    "    for file_path in file_paths:\n",
    "        matching_lines = []\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            # Go through each line and search for the pattern\n",
    "            for i, line in enumerate(file, 1):\n",
    "                if pattern.search(line):\n",
    "                    matching_lines.append(i)\n",
    "        \n",
    "        # Only store files that have matching lines\n",
    "        if matching_lines:\n",
    "            file_matches[os.path.basename(file_path)] = matching_lines\n",
    "    \n",
    "    return file_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc_data1.txt -> [1]\n"
     ]
    }
   ],
   "source": [
    "# Implement the Searching algorithm\n",
    "\n",
    "file_paths = [\"testcase/wc_data1.txt\", \"testcase/wc_data2.txt\"]\n",
    "search_pattern = \"beer\"\n",
    "\n",
    "matches = search_pattern_in_files(file_paths, search_pattern)\n",
    "\n",
    "# Print output in the format (file, [l1, l2, ...])\n",
    "for file, lines in matches.items():\n",
    "    print(f\"{file} -> {lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Scores:\n",
      "Germany: 0.0000\n",
      "I: -0.0405\n",
      "and: -0.0405\n",
      "beer: 0.0000\n",
      "craft: 0.0000\n",
      "drink: -0.0405\n",
      "in: -0.0405\n",
      "larger: 0.0000\n",
      "love: -0.0405\n"
     ]
    }
   ],
   "source": [
    "# Implement the TF-IDF computation algorithm\n",
    "\n",
    "# Reducer Function: Combines counts of the same word\n",
    "def reducer(sorted_output):\n",
    "    word_counts = defaultdict(int)\n",
    "    for word, count in sorted_output:\n",
    "        word_counts[word] += count\n",
    "    return word_counts\n",
    "\n",
    "# Calculate term frequency (TF) for each word in a document\n",
    "def compute_tf(word, word_count, total_words):\n",
    "    return word_count[word] / total_words\n",
    "\n",
    "# Calculate inverse document frequency (IDF) for a word\n",
    "def compute_idf(word, doc_count, total_docs):\n",
    "    return math.log(total_docs / (1 + doc_count.get(word, 0)))  # Add 1 to avoid division by zero\n",
    "\n",
    "# Main function to calculate TF-IDF\n",
    "def compute_tf_idf(word_counts, total_docs, doc_word_count):\n",
    "    total_words = sum(word_counts.values())\n",
    "    tf_idf = {}\n",
    "    \n",
    "    # Calculate TF-IDF for each word\n",
    "    for word in word_counts:\n",
    "        tf = compute_tf(word, word_counts, total_words)\n",
    "        idf = compute_idf(word, doc_word_count, total_docs)\n",
    "        tf_idf[word] = tf * idf\n",
    "    return tf_idf\n",
    "\n",
    "word_counts = reducer(sorted_output)\n",
    "\n",
    "# Count the number of documents each word appears in\n",
    "doc_word_count = defaultdict(int)\n",
    "total_docs = len(file_paths)\n",
    "\n",
    "for file in file_paths:\n",
    "    with open(file, 'r') as f:\n",
    "        words_in_file = set(f.read().split())\n",
    "        for word in words_in_file:\n",
    "            doc_word_count[word] += 1\n",
    "\n",
    "# Compute TF-IDF\n",
    "tf_idf_scores = compute_tf_idf(word_counts, total_docs, doc_word_count)\n",
    "\n",
    "# Print the TF-IDF Scores\n",
    "print(\"\\nTF-IDF Scores:\")\n",
    "for word, score in tf_idf_scores.items():\n",
    "    print(f'{word}: {score:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
